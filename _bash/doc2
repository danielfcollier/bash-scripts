#log dos arquivo utilizados para criar o reconhecimento

- gram é o arquivo que contem a gramatica - descreve as palavras a serem reconhecidas - usando HParse o HTK irá colocar a gram na sua linguagem - arquivo wdnet

- dict é o arquivo que contem o significado de cada palavra. Se o reconhecimeno fosse por fonema, seria necessário especificar cada palavra da gramatica em seus fonemas - é necessário que a ordem das palavras especificadas no dicionário seja alfabética - "cat file | uniq | sort > temp"

- HSGen pode gerar combinações das palavras (ou fonemas) especificados na gramática e no dicionário - útil pois gera possíveis frases para o treinamento

- O arquivo prompt.mlf é criado para especificar o que cada arquivo e áudio do treinamento possui. É necessário especificar  silencio no inicio e no final de cada gravaçao - HLed 

- prompt2.mlf é similar ao prompt.mlf, mas cada arquivo de áudio é especificado como .lab ao invés de .wav

- O arquivo config especifica todas as conversões dos parametros.

- arquivos.spc especifica os arquivos wav de treinamento, e seu futuro nome e endereçamento mfc - o comando HCopy irá opiar os .wav em .mfc (passa do dominio do tempo para da frequencia)

- inicialmente tudo é feito excluindo sp (short pause)

- arquivo proto inicial contém 12 estados (para reconhcimento de palavras é o suficiente) sendo que 2 são apenas estado inicial e final. Inicialmente as médias e variâncias para cada estado é colocada de forma abitrária. Na matriz de estados é necessário colocar probabilidade diferente e zero para os estados seguintes possiveis. Usando HCompV a média e a variância global são calculadas. O arquivo train.scp apenas possui os endereços dos arquvos de treinamento .mfl

- as médias e variânias globais são usadas como ponto de partida para a determinação de média e variância de cada palavra.

- hmmdefs é criado copiando o proto criado em hmm0 para cada uma das palavras (ou fonemas). Também deve-se criar o arquivo macros que é composto por um cabeçalho especificado no livro, mais o arquivo vFloors.

- com o HERest o que estava armazenado em hmm0 será reestimado.  Todos os modelos em hmm0 que estão listados na lista de modelo fones0 (contém cada palavra ou fonema do reconhecimento) serão carregados, estes são restimados usando a informação contida em train.scp e o novo modelo será armazenado em hmm1. cada vez que HERest é executado, uma nova reestimação é feita. A execução esse comando deve ser feita mais duas vezes, mudando o nome dos arquivos de entrada e de saída, até que o diretório hmm3 contenha o modelo final.

- agora é necessário colocar estados que pulam o seguinte. Ex: do 2 para o 4, e do 4 para o 2. A idéia aqui é fazer um modelo mais robusto que permita que estados individuais absorvam vários barulhos nos arquivos de treinamento.

- para adicionarmos o sp (short pause) no nosso modelo, é necessário copiar o hmmdefs da pasta hmm3 para a pasta hmm4, e nesse arquivo adicionamos um modelo sp com 3 estados, sendo que o estado 2 é idêntico ao estado 3 do sil. A matriz do estado 4 do sp terá a 1a  2a linha da matriz sil (3x3) e a última linha é nula, como sempre.

- agora é necessário adicionar sp no arquivo dos prompts entre as palavras, e também no arquivo de fones é necessário adicionar o modelo sp. Para adicionar sp entre as palavras no arquivo prompts2.mlf pode-se usar o comando HLed - ler no final do livro sobre esse comando. Então teremos fones1 e prompts1.mlf representando esses arquivos. Necessita-se de criar um arquivo sil.hed, com HHed atribui-se ao modelo sil uma probabilidade de 0.2 de mudança do estado 2 para 4; probabiliade 0.2 do estado 4 para 2; e para o modelo sp probabilidade 0.3 do estado 1 para o 3; e finalmente ele faz a ligação entre o estado 3 do sil e o etado 2 do sp.

- comando HVite possibilita modelos com mais de uma pronúncia.


Arquivo .mm salvo com o programa freemind